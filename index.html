<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Site Calibration Tool</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@stlite/mountable@0.73.1/build/stlite.css" />
</head>

<body>
  <div id="root"></div>
  <script src="https://cdn.jsdelivr.net/npm/@stlite/mountable@0.73.1/build/stlite.js"></script>
  <script>
    stlite.mount(
      {
        requirements: ["numpy", "pyproj", "pydantic>=2.0", "pandas", "altair==5.2.0", "tabulate"],
        entrypoint: "app.py",
        files: { "sitecal/__init__.py": "", "sitecal/core/__init__.py": "", "sitecal/domain/__init__.py": "", "sitecal/infrastructure/__init__.py": "", "app.py": "import streamlit as st\nimport pandas as pd\nimport io\nimport numpy as np\nimport altair as alt\n\n# Core Imports for Offline Processing\nfrom sitecal.core.calibration_engine import Similarity2D\nfrom sitecal.core.projections import ProjectionFactory\nfrom sitecal.infrastructure.reports import generate_markdown_report\n\nTOTAL_STEPS = 4\nSTEP_LABELS = [\n    \"1. Carga de Archivos\",\n    \"2. Mapeo y M\u00e9todo\",\n    \"3. Preview y Validaci\u00f3n\",\n    \"4. Resultados y Transformaci\u00f3n\",\n]\n\n\ndef validate_collinearity(df: pd.DataFrame) -> bool:\n    \"\"\"Checks for collinearity in points.\"\"\"\n    if \"Easting_global\" not in df.columns or \"Northing_global\" not in df.columns:\n        return False\n    coords = df[[\"Easting_global\", \"Northing_global\"]].values\n    if len(coords) < 3: return False\n    centered = coords - np.mean(coords, axis=0)\n    cov = np.cov(centered, rowvar=False)\n    eigvals = np.linalg.eigvals(cov)\n    if np.max(eigvals) == 0: return True\n    return (np.min(eigvals) / np.max(eigvals)) < 1e-4\n\n\ndef _init_state():\n    \"\"\"Initialize session_state defaults once.\"\"\"\n    defaults = {\n        \"step\": 1,\n        \"global_df\": None,\n        \"local_df\": None,\n        \"use_wls\": False,\n        \"col_map_g\": {},\n        \"col_map_l\": {},\n        \"method\": \"Default\",\n        \"params\": {},\n        \"merged_df\": None,\n        \"df_g_ready\": None,\n        \"df_g_proj\": None,\n        \"df_l_ready\": None,\n        \"cal_engine\": None,\n        \"cal_result\": None,\n    }\n    for k, v in defaults.items():\n        if k not in st.session_state:\n            st.session_state[k] = v\n\n\ndef _go(step: int):\n    st.session_state[\"step\"] = step\n\n\ndef _reset_calibration():\n    for k in [\"cal_result\", \"cal_engine\", \"merged_df\", \"df_g_ready\", \"df_g_proj\", \"df_l_ready\"]:\n        st.session_state[k] = None\n    st.session_state[\"step\"] = 1\n\n\n# \u2500\u2500 Progress bar \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _render_progress():\n    step = st.session_state[\"step\"]\n    st.progress(step / TOTAL_STEPS)\n    st.caption(f\"Paso {step} de {TOTAL_STEPS} \u2014 {STEP_LABELS[step - 1]}\")\n\n\n# \u2500\u2500 Step 1: File Upload \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _step_upload():\n    st.header(\"Paso 1 \u2014 Carga de Archivos CSV\")\n\n    with st.expander(\"\u2139\ufe0f Instrucciones de Formato CSV (Importante)\"):\n        st.markdown(\"\"\"\n        ### Archivo Global (GNSS)\n        **Formato:** Coordenadas Geod\u00e9sicas WGS84 (Grados Decimales)\n        * **Columnas Requeridas:** `Point` (ID), `Latitude`, `Longitude`, `Ellipsoidal Height` (o `h`)\n        * **Precisi\u00f3n:** Al menos **8 decimales** en Lat/Lon para asegurar precisi\u00f3n milim\u00e9trica.\n\n        ### Archivo Local (Planas)\n        **Formato:** Coordenadas Cartesianas Locales (Metros)\n        * **Columnas Requeridas:** `Point` (ID), `Easting` (Este), `Northing` (Norte), `Elevation` (o `z`, `h`)\n        \"\"\")\n\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.info(\"\ud83c\udf10 Coordenadas Globales (GNSS / WGS84)\")\n        global_file = st.file_uploader(\"Subir CSV Global\", type=[\"csv\"], key=\"global\")\n        if global_file:\n            has_header_g = st.checkbox(\"Tiene encabezados\", value=True, key=\"header_g\")\n            gdf = pd.read_csv(global_file, header=0 if has_header_g else None)\n            st.session_state[\"global_df\"] = gdf\n            st.dataframe(gdf.head(), use_container_width=True)\n        else:\n            st.session_state[\"global_df\"] = None\n\n    with col2:\n        st.info(\"\ud83d\udcd0 Coordenadas Locales (Planas / Metros)\")\n        local_file = st.file_uploader(\"Subir CSV Local\", type=[\"csv\"], key=\"local\")\n        if local_file:\n            has_header_l = st.checkbox(\"Tiene encabezados\", value=True, key=\"header_l\")\n            ldf = pd.read_csv(local_file, header=0 if has_header_l else None)\n\n            use_wls = st.checkbox(\"Ingresar precisi\u00f3n por punto (WLS)\", value=False, key=\"use_wls_cb\")\n            st.session_state[\"use_wls\"] = use_wls\n            if use_wls:\n                if \"sigma\" not in ldf.columns:\n                    ldf[\"sigma\"] = 1.0\n                st.caption(\"Edita la columna 'sigma' para aplicar pesos personalizados (WLS):\")\n                ldf = st.data_editor(ldf, num_rows=\"dynamic\", key=\"local_editor\")\n            else:\n                st.dataframe(ldf.head(), use_container_width=True)\n\n            st.session_state[\"local_df\"] = ldf\n        else:\n            st.session_state[\"local_df\"] = None\n\n    # Navigation\n    st.markdown(\"---\")\n    both_ready = st.session_state[\"global_df\"] is not None and st.session_state[\"local_df\"] is not None\n    if not both_ready:\n        st.info(\"Sube ambos archivos CSV para continuar.\")\n    st.button(\"Siguiente \u2192\", disabled=not both_ready, on_click=_go, args=(2,), type=\"primary\", use_container_width=True)\n\n\n# \u2500\u2500 Step 2: Column Mapping + Method \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _step_mapping():\n    st.header(\"Paso 2 \u2014 Mapeo de Columnas y M\u00e9todo\")\n\n    global_df = st.session_state[\"global_df\"]\n    local_df = st.session_state[\"local_df\"]\n\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.subheader(\"Columnas Globales\")\n        st.dataframe(global_df.head(3), use_container_width=True)\n        cols_g = global_df.columns.tolist()\n        g_point = st.selectbox(\"Point (ID)\", cols_g, index=0, key=\"g_pt\")\n        g_lat = st.selectbox(\"Latitude\", cols_g, index=1 if len(cols_g) > 1 else 0, key=\"g_lat\")\n        g_lon = st.selectbox(\"Longitude\", cols_g, index=2 if len(cols_g) > 2 else 0, key=\"g_lon\")\n        g_h = st.selectbox(\"Ellipsoidal Height\", cols_g, index=3 if len(cols_g) > 3 else 0, key=\"g_h\")\n\n    with col2:\n        st.subheader(\"Columnas Locales\")\n        st.dataframe(local_df.head(3), use_container_width=True)\n        cols_l = local_df.columns.tolist()\n        l_point = st.selectbox(\"Point (ID)\", cols_l, index=0, key=\"l_pt\")\n        l_e = st.selectbox(\"Easting\", cols_l, index=1 if len(cols_l) > 1 else 0, key=\"l_e\")\n        l_n = st.selectbox(\"Northing\", cols_l, index=2 if len(cols_l) > 2 else 0, key=\"l_n\")\n        l_z = st.selectbox(\"Elevation\", cols_l, index=3 if len(cols_l) > 3 else 0, key=\"l_z\")\n\n        st.markdown(\"##### Geometr\u00eda Local\")\n        try:\n            chart_data = local_df.rename(columns={l_e: \"Easting\", l_n: \"Northing\"})\n            st.scatter_chart(chart_data, x=\"Easting\", y=\"Northing\", color=\"#FF4B4B\")\n        except Exception:\n            st.caption(\"No se pudo generar la previsualizaci\u00f3n gr\u00e1fica.\")\n\n    # Store column mapping\n    st.session_state[\"col_map_g\"] = {\"Point\": g_point, \"Latitude\": g_lat, \"Longitude\": g_lon, \"EllipsoidalHeight\": g_h}\n    st.session_state[\"col_map_l\"] = {\"Point\": l_point, \"Easting\": l_e, \"Northing\": l_n, \"Elevation\": l_z}\n\n    # Method selection\n    st.subheader(\"M\u00e9todo y Par\u00e1metros\")\n    col_method, col_params = st.columns([1, 3])\n\n    with col_method:\n        method = st.selectbox(\"Seleccionar M\u00e9todo\", [\"Default\", \"LTM\", \"EPSG\"])\n    st.session_state[\"method\"] = method\n\n    params = {}\n    if method == \"LTM\":\n        with col_params:\n            c1, c2, c3, c4 = st.columns(4)\n            with c1: params[\"central_meridian\"] = st.number_input(\"Meridiano Central\", value=-72.0)\n            with c2: params[\"scale_factor\"] = st.number_input(\"Factor de Escala\", value=0.9996, format=\"%.6f\")\n            with c3: params[\"false_easting\"] = st.number_input(\"Falso Este\", value=500000.0)\n            with c4: params[\"false_northing\"] = st.number_input(\"Falso Norte\", value=10000000.0)\n    elif method == \"EPSG\":\n        with col_params:\n            params[\"epsg_code\"] = st.number_input(\n                \"C\u00f3digo EPSG\",\n                value=32719,\n                min_value=1024,\n                max_value=32767,\n                step=1,\n                help=\"Ej: 32719 = WGS 84 / UTM zone 19S, 32718 = UTM 18S, 5361 = PSAD56 / Peru West Zone\",\n            )\n    st.session_state[\"params\"] = params\n\n    # Navigation\n    st.markdown(\"---\")\n    c_back, c_next = st.columns(2)\n    with c_back:\n        st.button(\"\u2190 Atr\u00e1s\", on_click=_go, args=(1,), use_container_width=True)\n    with c_next:\n        st.button(\"Siguiente \u2192\", on_click=_go, args=(3,), type=\"primary\", use_container_width=True)\n\n\n# \u2500\u2500 Step 3: Preview + Validations \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _step_preview():\n    st.header(\"Paso 3 \u2014 Preview y Validaci\u00f3n\")\n\n    global_df = st.session_state[\"global_df\"]\n    local_df = st.session_state[\"local_df\"]\n    cmap_g = st.session_state[\"col_map_g\"]\n    cmap_l = st.session_state[\"col_map_l\"]\n    method = st.session_state[\"method\"]\n    params = st.session_state[\"params\"]\n    use_wls = st.session_state[\"use_wls\"]\n\n    try:\n        # Standardize global\n        df_g_ready = global_df.rename(columns={\n            cmap_g[\"Point\"]: \"Point\",\n            cmap_g[\"Latitude\"]: \"Latitude\",\n            cmap_g[\"Longitude\"]: \"Longitude\",\n            cmap_g[\"EllipsoidalHeight\"]: \"EllipsoidalHeight\",\n        })[[\"Point\", \"Latitude\", \"Longitude\", \"EllipsoidalHeight\"]]\n        df_g_ready[\"Point\"] = df_g_ready[\"Point\"].astype(str)\n\n        # Standardize local\n        cols_to_keep_l = [\"Point\", \"Easting\", \"Northing\", \"Elevation\"]\n        if \"sigma\" in local_df.columns and use_wls:\n            cols_to_keep_l.append(\"sigma\")\n\n        df_l_ready = local_df.rename(columns={\n            cmap_l[\"Point\"]: \"Point\",\n            cmap_l[\"Easting\"]: \"Easting\",\n            cmap_l[\"Northing\"]: \"Northing\",\n            cmap_l[\"Elevation\"]: \"Elevation\",\n        })[cols_to_keep_l]\n        df_l_ready[\"Point\"] = df_l_ready[\"Point\"].astype(str)\n\n        # Project\n        proj_params = {k: v for k, v in params.items()}\n        projection = ProjectionFactory.create(method.lower(), **proj_params)\n        df_g_proj = projection.project(df_g_ready)\n\n        # Merge\n        merged_df = pd.merge(df_l_ready, df_g_proj, on=\"Point\", suffixes=('_local', '_global'))\n\n        # Store for step 4\n        st.session_state[\"df_g_ready\"] = df_g_ready\n        st.session_state[\"df_g_proj\"] = df_g_proj\n        st.session_state[\"df_l_ready\"] = df_l_ready\n        st.session_state[\"merged_df\"] = merged_df\n\n    except Exception as e:\n        st.error(f\"Error preparando datos: {e}\")\n        st.button(\"\u2190 Atr\u00e1s\", on_click=_go, args=(2,), use_container_width=True)\n        return\n\n    n = len(merged_df)\n\n    # Unmatched points\n    global_points = set(df_g_ready[\"Point\"])\n    local_points = set(df_l_ready[\"Point\"])\n    only_in_global = global_points - local_points\n    only_in_local = local_points - global_points\n    if only_in_global or only_in_local:\n        st.subheader(\"Puntos sin par\")\n        if only_in_global:\n            st.warning(\n                f\"**{len(only_in_global)} punto(s) en global sin par en local:** \"\n                f\"{', '.join(sorted(only_in_global))}\"\n            )\n        if only_in_local:\n            st.warning(\n                f\"**{len(only_in_local)} punto(s) en local sin par en global:** \"\n                f\"{', '.join(sorted(only_in_local))}\"\n            )\n\n    # Common points table with fixed column order\n    st.subheader(f\"Puntos comunes detectados: {n}\")\n    display_cols = [\"Point\", \"Easting_local\", \"Northing_local\", \"Elevation\",\n                    \"Easting_global\", \"Northing_global\", \"EllipsoidalHeight\"]\n    display_cols = [c for c in display_cols if c in merged_df.columns]\n    st.dataframe(merged_df[display_cols], use_container_width=True)\n\n    # Validations\n    errors = []\n    if n < 3:\n        errors.append(f\"Solo se encontraron **{n}** puntos comunes. Se requieren m\u00ednimo 3.\")\n    if n >= 3 and validate_collinearity(merged_df):\n        errors.append(\"Los puntos son colineales o geogr\u00e1ficamente muy cercanos. Geometr\u00eda inestable.\")\n\n    if errors:\n        for e in errors:\n            st.error(e)\n        can_proceed = False\n    else:\n        bbox_str = \"\"\n        if \"Easting_local\" in merged_df.columns and \"Northing_local\" in merged_df.columns:\n            e_min, e_max = merged_df[\"Easting_local\"].min(), merged_df[\"Easting_local\"].max()\n            n_min, n_max = merged_df[\"Northing_local\"].min(), merged_df[\"Northing_local\"].max()\n            bbox_str = (\n                f\" | BBox local: {e_max - e_min:.2f} m (E) \u00d7 {n_max - n_min:.2f} m (N)\"\n            )\n        st.success(f\"{n} puntos comunes v\u00e1lidos. Geometr\u00eda aceptable.{bbox_str}\")\n        can_proceed = True\n\n    # \u2500\u2500 Scatter dual: Global proyectado vs Local \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    if n >= 3 and \"Easting_global\" in merged_df.columns and \"Easting_local\" in merged_df.columns:\n        df_g_plot = merged_df[[\"Point\", \"Easting_global\", \"Northing_global\"]].copy()\n        df_l_plot = merged_df[[\"Point\", \"Easting_local\", \"Northing_local\"]].copy()\n\n        pts_g = alt.Chart(df_g_plot).mark_circle(size=80, color=\"#1f77b4\").encode(\n            x=alt.X(\"Easting_global:Q\", scale=alt.Scale(zero=False), title=\"Easting (m)\"),\n            y=alt.Y(\"Northing_global:Q\", scale=alt.Scale(zero=False), title=\"Northing (m)\"),\n            tooltip=[\"Point:N\", \"Easting_global:Q\", \"Northing_global:Q\"],\n        )\n        pts_l = alt.Chart(df_l_plot).mark_circle(size=80, color=\"#d62728\").encode(\n            x=alt.X(\"Easting_local:Q\", scale=alt.Scale(zero=False), title=\"Easting (m)\"),\n            y=alt.Y(\"Northing_local:Q\", scale=alt.Scale(zero=False), title=\"Northing (m)\"),\n            tooltip=[\"Point:N\", \"Easting_local:Q\", \"Northing_local:Q\"],\n        )\n        st.altair_chart(\n            alt.layer(pts_g, pts_l).properties(\n                title=\"Vista previa: Global proyectado vs Local\",\n                height=350,\n            ),\n            use_container_width=True,\n        )\n\n    # Navigation\n    st.markdown(\"---\")\n    c_back, c_next = st.columns(2)\n    with c_back:\n        st.button(\"\u2190 Atr\u00e1s\", on_click=_go, args=(2,), use_container_width=True)\n    with c_next:\n        st.button(\"Calcular Calibraci\u00f3n \u2192\", disabled=not can_proceed, on_click=_go, args=(4,), type=\"primary\", use_container_width=True)\n\n\n# \u2500\u2500 Step 4: Calibration + Results + Transform \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _step_results():\n    st.header(\"Paso 4 \u2014 Resultados de Calibraci\u00f3n\")\n\n    df_g_ready = st.session_state[\"df_g_ready\"]\n    df_g_proj = st.session_state[\"df_g_proj\"]\n    df_l_ready = st.session_state[\"df_l_ready\"]\n    method = st.session_state[\"method\"]\n    params = st.session_state[\"params\"]\n\n    # Run calibration (once per visit \u2014 cached in session_state)\n    if st.session_state.get(\"cal_result\") is None:\n        with st.spinner(\"Procesando localmente...\"):\n            try:\n                import warnings\n                engine = Similarity2D()\n\n                # Capture projection params for serialization\n                engine.proj_method = method.lower()\n                adj_params = params.copy()\n                if engine.proj_method == \"default\":\n                    adj_params[\"lat_0\"] = float(df_g_ready.iloc[0][\"Latitude\"])\n                    adj_params[\"lon_0\"] = float(df_g_ready.iloc[0][\"Longitude\"])\n                elif engine.proj_method == \"utm\":\n                    lon_mean = df_g_ready[\"Longitude\"].mean()\n                    utm_zone = int((lon_mean + 180) / 6) + 1\n                    is_south = df_g_ready[\"Latitude\"].mean() < 0\n                    adj_params[\"utm_zone\"] = utm_zone\n                    adj_params[\"is_south\"] = is_south\n                elif engine.proj_method == \"ltm\":\n                    adj_params[\"latitude_of_origin\"] = 0.0\n                elif engine.proj_method == \"epsg\":\n                    adj_params[\"epsg_code\"] = int(params.get(\"epsg_code\", 32719))\n                engine.proj_params = adj_params\n\n                with warnings.catch_warnings(record=True) as w:\n                    warnings.simplefilter(\"always\")\n                    engine.train(df_l_ready, df_g_proj)\n                    for warn in w:\n                        if \"Extrapolaci\u00f3n detectada\" in str(warn.message):\n                            st.warning(str(warn.message), icon=\"\u26a0\ufe0f\")\n\n                # Build result\n                residuals = []\n                for _, row in engine.residuals.iterrows():\n                    res_dict = {\n                        \"Point\": str(row[\"Point\"]),\n                        \"dE\": float(row[\"dE\"]),\n                        \"dN\": float(row[\"dN\"]),\n                        \"dH\": float(row[\"dH\"]),\n                    }\n                    if \"outlier_horizontal\" in engine.residuals.columns:\n                        res_dict[\"outlier_horizontal\"] = bool(row.get(\"outlier_horizontal\", False))\n                    if \"outlier_vertical\" in engine.residuals.columns:\n                        res_dict[\"outlier_vertical\"] = bool(row.get(\"outlier_vertical\", False))\n                    residuals.append(res_dict)\n\n                report_text = generate_markdown_report(engine, \"not_used\", method.lower())\n\n                result_data = {\n                    \"parameters\": {\n                        \"horizontal\": engine.horizontal_params,\n                        \"vertical\": engine.vertical_params,\n                    },\n                    \"residuals\": residuals,\n                    \"report\": report_text,\n                }\n\n                st.session_state[\"cal_engine\"] = engine\n                st.session_state[\"cal_result\"] = result_data\n\n            except Exception as e:\n                st.error(f\"Error Interno: {str(e)}\")\n                st.button(\"\u2190 Atr\u00e1s\", on_click=_go, args=(3,), use_container_width=True)\n                return\n\n    result_data = st.session_state[\"cal_result\"]\n    engine = st.session_state[\"cal_engine\"]\n\n    display_results(result_data)\n\n    st.download_button(\n        label=\"\ud83d\udcbe Descargar Calibraci\u00f3n (.sitecal)\",\n        data=engine.save(),\n        file_name=\"calibracion.sitecal\",\n        mime=\"application/json\",\n        use_container_width=True,\n    )\n\n    # \u2500\u2500 Transform section \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    st.divider()\n    st.header(\"Transformar Puntos\")\n    st.markdown(\"Aplica una calibraci\u00f3n existente a un nuevo conjunto de puntos.\")\n\n    load_col, _ = st.columns(2)\n    with load_col:\n        st.subheader(\"Modelo de Calibraci\u00f3n\")\n        cal_file = st.file_uploader(\"Cargar Calibraci\u00f3n (.sitecal)\", type=[\"sitecal\", \"json\"])\n\n        loaded_engine = None\n        if cal_file:\n            try:\n                content = cal_file.read().decode('utf-8')\n                loaded_engine = Similarity2D.load(content)\n                st.success(\"\u2705 Modelo cargado desde archivo.\")\n            except Exception as e:\n                st.error(f\"Error cargando archivo: {str(e)}\")\n        elif st.session_state.get(\"cal_engine\") is not None:\n            loaded_engine = st.session_state[\"cal_engine\"]\n            st.info(\"\u2139\ufe0f Usando el modelo de calibraci\u00f3n calculado en la sesi\u00f3n actual.\")\n        else:\n            st.warning(\"\u26a0\ufe0f Debes calcular una calibraci\u00f3n arriba o subir un archivo `.sitecal`.\")\n\n    if loaded_engine is not None:\n        st.subheader(\"Puntos a Transformar\")\n        trans_file = st.file_uploader(\"Subir CSV de Puntos\", type=[\"csv\"], key=\"trans_points\")\n\n        if trans_file:\n            trans_df = pd.read_csv(trans_file)\n            st.dataframe(trans_df.head(), use_container_width=True)\n            col_names = \", \".join(trans_df.columns.tolist())\n            st.caption(f\"{len(trans_df)} puntos detectados | Columnas: {col_names}\")\n\n            direction = st.radio(\"Direcci\u00f3n de Transformaci\u00f3n\", [\"Global -> Local\", \"Local -> Global\"])\n\n            tc = trans_df.columns.tolist()\n            t_id = st.selectbox(\"Point (ID)\", tc, index=0, key=\"t_id\")\n            if direction == \"Global -> Local\":\n                t_x = st.selectbox(\"Easting Global / Longitude\", tc, index=1 if len(tc) > 1 else 0, key=\"t_g_e\")\n                t_y = st.selectbox(\"Northing Global / Latitude\", tc, index=2 if len(tc) > 2 else 0, key=\"t_g_n\")\n                t_z = st.selectbox(\"Ellipsoidal Height / h\", tc, index=3 if len(tc) > 3 else 0, key=\"t_g_h\")\n            else:\n                t_x = st.selectbox(\"Easting (Local)\", tc, index=1 if len(tc) > 1 else 0, key=\"t_l_e\")\n                t_y = st.selectbox(\"Northing (Local)\", tc, index=2 if len(tc) > 2 else 0, key=\"t_l_n\")\n                t_z = st.selectbox(\"Elevation (Local)\", tc, index=3 if len(tc) > 3 else 0, key=\"t_l_h\")\n\n            dup_mask = trans_df[t_id].duplicated(keep=False)\n            if dup_mask.any():\n                dup_ids = trans_df[t_id][dup_mask].unique().tolist()\n                st.warning(f\"IDs duplicados en columna '{t_id}': {', '.join(str(i) for i in dup_ids)}\")\n\n            if st.button(\"Aplicar Transformaci\u00f3n\", type=\"primary\", key=\"btn_trans\"):\n                with st.spinner(\"Transformando...\"):\n                    try:\n                        if direction == \"Global -> Local\":\n                            df_ready = trans_df.rename(columns={\n                                t_id: \"Point\", t_x: \"Longitude\", t_y: \"Latitude\", t_z: \"EllipsoidalHeight\"\n                            })[[\"Point\", \"Longitude\", \"Latitude\", \"EllipsoidalHeight\"]]\n                            df_ready[\"Point\"] = df_ready[\"Point\"].astype(str)\n\n                            if loaded_engine.proj_method:\n                                from pyproj import CRS, Transformer as _T\n                                _src, _dst = loaded_engine.get_crs_strings()\n                                if _dst:\n                                    _tf = _T.from_crs(CRS(_src), CRS(_dst), always_xy=True)\n                                    df_ready[\"Easting_global\"], df_ready[\"Northing_global\"] = \\\n                                        _tf.transform(df_ready[\"Longitude\"].values,\n                                                      df_ready[\"Latitude\"].values)\n                                else:\n                                    df_ready = df_ready.rename(columns={\n                                        \"Longitude\": \"Easting_global\", \"Latitude\": \"Northing_global\"})\n                            else:\n                                df_ready = df_ready.rename(columns={\n                                    \"Longitude\": \"Easting_global\", \"Latitude\": \"Northing_global\"})\n\n                            res_df = loaded_engine.transform(df_ready)\n                        else:\n                            df_ready = trans_df.rename(columns={\n                                t_id: \"Point\", t_x: \"Easting_local\", t_y: \"Northing_local\", t_z: \"Elevation\"\n                            })[[\"Point\", \"Easting_local\", \"Northing_local\", \"Elevation\"]]\n                            df_ready[\"Point\"] = df_ready[\"Point\"].astype(str)\n\n                            res_df = loaded_engine.transform_inverse(df_ready)\n\n                        st.success(\"Transformaci\u00f3n exitosa.\")\n                        st.dataframe(res_df.head(), use_container_width=True)\n\n                        csv_data = res_df.to_csv(index=False).encode('utf-8')\n                        st.download_button(\n                            label=\"\ud83d\udce5 Descargar Resultados CSV\",\n                            data=csv_data,\n                            file_name=\"puntos_transformados.csv\",\n                            mime=\"text/csv\",\n                        )\n                    except Exception as e:\n                        st.error(f\"Error transformando puntos: {str(e)}\")\n\n    # Navigation\n    st.divider()\n    st.button(\"\u2190 Atr\u00e1s (Preview)\", on_click=_go, args=(3,), use_container_width=True)\n\n\n# \u2500\u2500 Display results (unchanged logic) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef display_results(data):\n    # 1. Calculated Parameters\n    if \"parameters\" in data:\n        p = data[\"parameters\"]\n\n        if \"horizontal\" in p and p[\"horizontal\"]:\n            st.subheader(\"\ud83c\udfd7\ufe0f Ajuste Horizontal (2D)\")\n            hp = p[\"horizontal\"]\n            c1, c2, c3, c4 = st.columns(4)\n            with c1: st.metric(\"Factor Escala (a)\", f\"{hp['a']:.7f}\")\n            with c2: st.metric(\"Rotaci\u00f3n (b)\", f\"{hp['b']:.7f}\")\n            with c3: st.metric(\"Traslasi\u00f3n Este\", f\"{hp['tE']:.3f} m\")\n            with c4: st.metric(\"Traslasi\u00f3n Norte\", f\"{hp['tN']:.3f} m\")\n\n        if \"vertical\" in p and p[\"vertical\"]:\n            st.subheader(\"\ud83d\udcd0 Ajuste Vertical (1D)\")\n            vp = p[\"vertical\"]\n            c1, c2, c3, c4 = st.columns(4)\n            with c1: st.metric(\"Shift Vertical\", f\"{vp['vertical_shift']:.3f} m\")\n            with c2: st.metric(\"Inclinaci\u00f3n N\", f\"{vp['slope_north']*1e6:.2f} ppm\")\n            with c3: st.metric(\"Inclinaci\u00f3n E\", f\"{vp['slope_east']*1e6:.2f} ppm\")\n            with c4: st.metric(\"Centroide\", f\"({vp['centroid_north']:.0f}, {vp['centroid_east']:.0f})\")\n\n        st.markdown(\"---\")\n\n    # 2. Fit Quality Section\n    if \"residuals\" in data and \"parameters\" in data:\n        p = data[\"parameters\"]\n        hp = p.get(\"horizontal\", {})\n\n        sigma0_sq = hp.get(\"sigma0_sq_h\")\n        residuals_list = data[\"residuals\"]\n\n        if residuals_list:\n            if sigma0_sq is not None:\n                sigma0 = np.sqrt(sigma0_sq)\n            else:\n                df_res_tmp = pd.DataFrame(residuals_list)\n                dof = max(1, 2 * len(df_res_tmp) - 4)\n                v_sq = df_res_tmp[\"dE\"]**2 + df_res_tmp[\"dN\"]**2\n                sigma0 = np.sqrt(v_sq.sum() / dof)\n\n            st.subheader(\"\ud83c\udfaf Calidad del Ajuste (Horizontal)\")\n            if sigma0 < 0.005:\n                color, status = \"green\", \"Excelente\"\n            elif sigma0 < 0.02:\n                color, status = \"orange\", \"Aceptable\"\n            else:\n                color, status = \"red\", \"Pobre\"\n\n            st.markdown(f\"**Varianza a Posteriori ($\\\\sigma_0$):** :{color}[**{sigma0:.4f} m** ({status})]\")\n            st.markdown(\"---\")\n\n    # 3. Residuals Table\n    if \"residuals\" in data:\n        st.subheader(\"Cuadr\u00edcula de Residuales\")\n        residuals = data[\"residuals\"]\n        if isinstance(residuals, list) and len(residuals) > 0:\n            df = pd.DataFrame(residuals)\n\n            def highlight_outliers(row):\n                is_outlier = row.get(\"outlier_horizontal\", False) or row.get(\"outlier_vertical\", False)\n                color = 'background-color: #ffcccc; color: #900' if is_outlier else ''\n                return [color] * len(row)\n\n            display_df = df.copy()\n            if \"outlier_horizontal\" in display_df.columns:\n                display_df[\"outlier_horizontal\"] = display_df[\"outlier_horizontal\"].apply(lambda x: \"\u26a0\ufe0f Outlier\" if x else \"\u2705\")\n            if \"outlier_vertical\" in display_df.columns:\n                display_df[\"outlier_vertical\"] = display_df[\"outlier_vertical\"].apply(lambda x: \"\u26a0\ufe0f Outlier\" if x else \"\u2705\")\n\n            display_df.rename(columns={\"dE\": \"dE (m)\", \"dN\": \"dN (m)\", \"dH\": \"dH (m)\"}, inplace=True)\n            st.dataframe(display_df.style.apply(highlight_outliers, axis=1), use_container_width=True)\n\n            # \u2500\u2500 Scatter de residuales horizontales \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n            df_res = df[[\"Point\", \"dE\", \"dN\"]].copy()\n            if \"outlier_horizontal\" in df.columns:\n                df_res[\"_tipo\"] = df[\"outlier_horizontal\"].apply(\n                    lambda x: \"Outlier\" if x else \"Normal\"\n                )\n            else:\n                df_res[\"_tipo\"] = \"Normal\"\n\n            zero_h = alt.Chart(pd.DataFrame({\"y\": [0.0]})).mark_rule(\n                color=\"gray\", strokeDash=[4, 4], opacity=0.7\n            ).encode(y=\"y:Q\")\n            zero_v = alt.Chart(pd.DataFrame({\"x\": [0.0]})).mark_rule(\n                color=\"gray\", strokeDash=[4, 4], opacity=0.7\n            ).encode(x=\"x:Q\")\n            pts_res = alt.Chart(df_res).mark_circle(size=80).encode(\n                x=alt.X(\"dE:Q\", title=\"dE (m)\"),\n                y=alt.Y(\"dN:Q\", title=\"dN (m)\"),\n                color=alt.Color(\n                    \"_tipo:N\",\n                    scale=alt.Scale(domain=[\"Normal\", \"Outlier\"], range=[\"#2ca02c\", \"#d62728\"]),\n                    legend=alt.Legend(title=\"Tipo\"),\n                ),\n                tooltip=[\"Point:N\", \"dE:Q\", \"dN:Q\"],\n            )\n            origin = alt.Chart(pd.DataFrame({\"x\": [0.0], \"y\": [0.0]})).mark_point(\n                shape=\"diamond\", size=150, color=\"black\", filled=True, opacity=0.6\n            ).encode(x=\"x:Q\", y=\"y:Q\")\n            st.altair_chart(\n                alt.layer(zero_h, zero_v, pts_res, origin).properties(\n                    title=\"Residuales horizontales (dE vs dN)\",\n                    height=350,\n                ),\n                use_container_width=True,\n            )\n        else:\n            st.info(\"No se devolvieron datos de residuales.\")\n        st.markdown(\"---\")\n\n    # 4. Full Report\n    report_md = data.get(\"report\") or data.get(\"markdown_report\")\n    if report_md:\n        st.subheader(\"Reporte Completo de Calibraci\u00f3n\")\n        st.markdown(report_md)\n\n        import markdown as _md\n        html_body = _md.markdown(report_md, extensions=[\"tables\"])\n        html_content = (\n            \"<!DOCTYPE html>\\n<html>\\n<head>\\n\"\n            '  <meta charset=\"UTF-8\">\\n'\n            \"  <title>Site Calibration Report</title>\\n\"\n            \"  <style>\\n\"\n            \"    body { font-family: sans-serif; max-width: 800px; margin: 0 auto; padding: 2rem; }\\n\"\n            \"    h1, h2, h3 { color: #2c3e50; }\\n\"\n            \"    table { border-collapse: collapse; width: 100%; }\\n\"\n            \"    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\\n\"\n            \"    th { background-color: #f5f5f5; }\\n\"\n            \"    pre { background: #f8f8f8; padding: 1rem; border-radius: 4px; overflow-x: auto; }\\n\"\n            \"  </style>\\n\"\n            \"</head>\\n<body>\\n\"\n            \"  <h1>Site Calibration Report</h1>\\n\"\n            f\"  {html_body}\\n\"\n            \"</body>\\n</html>\"\n        )\n        st.download_button(\n            label=\"\ud83d\udcc4 Descargar Reporte HTML\",\n            data=html_content.encode(\"utf-8\"),\n            file_name=\"reporte_calibracion.html\",\n            mime=\"text/html\",\n        )\n\n\n# \u2500\u2500 Main \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef main():\n    st.set_page_config(page_title=\"Site Calibration (Offline)\", page_icon=\"\ud83d\udef0\ufe0f\", layout=\"wide\")\n    _init_state()\n\n    # \u2500\u2500 Sidebar \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    st.sidebar.title(\"\ud83d\udef0\ufe0f Site Calibration\")\n    st.sidebar.caption(\"Calibraci\u00f3n geod\u00e9sica local y offline\")\n    st.sidebar.divider()\n    step = st.session_state[\"step\"]\n    st.sidebar.markdown(\"**Paso actual:**\")\n    st.sidebar.info(STEP_LABELS[step - 1])\n    st.sidebar.divider()\n    st.sidebar.button(\n        \"\ud83d\udd04 Nueva Calibraci\u00f3n\",\n        on_click=_reset_calibration,\n        use_container_width=True,\n        help=\"Reinicia el flujo y borra los resultados actuales\",\n    )\n\n    # \u2500\u2500 Main area \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    st.title(\"\ud83d\udef0\ufe0f Site Calibration Tool\")\n    st.caption(\"v1.0 \u00b7 Calibraci\u00f3n de sitio geod\u00e9sica \u00b7 Procesamiento local, sin conexi\u00f3n a internet\")\n\n    _render_progress()\n\n    if step == 1:\n        _step_upload()\n    elif step == 2:\n        _step_mapping()\n    elif step == 3:\n        _step_preview()\n    elif step == 4:\n        _step_results()\n\n\nif __name__ == \"__main__\":\n    main()\n", "sitecal/core/calibration_engine.py": "import json\nfrom datetime import datetime\nfrom abc import ABC, abstractmethod\nimport numpy as np\nimport pandas as pd\nfrom sitecal.domain.schemas import PointLocal, PointGlobal, PointTransform, HorizontalParams, VerticalParams\nfrom sitecal.core.math_engine import calculate_wls_similarity, calculate_wls_vertical, check_extrapolation\n\n\nclass Calibration(ABC):\n    @abstractmethod\n    def train(self, df_local: pd.DataFrame, df_global: pd.DataFrame):\n        pass\n\n    @abstractmethod\n    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n        pass\n\n    @abstractmethod\n    def save(self) -> str:\n        \"\"\"Serializes the calibrated model to a JSON string.\"\"\"\n        pass\n\n    @classmethod\n    @abstractmethod\n    def load(cls, json_str: str) -> 'Calibration':\n        \"\"\"Deserializes a JSON string into a Calibration model.\"\"\"\n        pass\n\n\nclass Similarity2D(Calibration):\n    def __init__(self):\n        self.horizontal_params = None\n        self.vertical_params = None\n        self.residuals = None\n        self.proj_method = None\n        self.proj_params = {}\n\n    def get_crs_strings(self):\n        m = self.proj_method\n        p = self.proj_params\n        if m == \"default\":\n            lat_0 = p.get(\"lat_0\", 0.0)\n            lon_0 = p.get(\"lon_0\", 0.0)\n            proj = (f\"+proj=tmerc +lat_0={lat_0} +lon_0={lon_0} \"\n                    f\"+k=1.0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n        elif m == \"utm\":\n            zone = p.get(\"utm_zone\", 19)\n            south = p.get(\"is_south\", True)\n            code = 32700 + zone if south else 32600 + zone\n            proj = f\"EPSG:{code}\"\n        elif m == \"ltm\":\n            proj = (f\"+proj=tmerc +lat_0={p.get('latitude_of_origin', 0.0)} \"\n                    f\"+lon_0={p.get('central_meridian', -72.0)} \"\n                    f\"+k={p.get('scale_factor', 0.9996)} \"\n                    f\"+x_0={p.get('false_easting', 500000.0)} \"\n                    f\"+y_0={p.get('false_northing', 10000000.0)} \"\n                    f\"+ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n        elif m == \"epsg\":\n            proj = f\"EPSG:{p.get('epsg_code', 32719)}\"\n        else:\n            proj = None\n        return \"EPSG:4326\", proj\n\n    def train(self, df_local: pd.DataFrame, df_global: pd.DataFrame):\n        \"\"\"\n        Calculates 2D similarity transformation parameters (a, b, tE, tN)\n        and Vertical Adjustment parameters (Inclined Plane or Constant Shift).\n        \"\"\"\n        \n        # Pydantic validation for input DataFrames\n        local_pts = [PointLocal(**row) for row in df_local.to_dict('records')]\n        global_pts = [PointGlobal(**row) for row in df_global.to_dict('records')]\n\n        merged_df = pd.merge(df_local, df_global, on=\"Point\", suffixes=('_local', '_global'))\n        n = len(merged_df)\n\n        # Extract values\n        x = merged_df[\"Easting_global\"].values\n        y = merged_df[\"Northing_global\"].values\n        E = merged_df[\"Easting_local\"].values\n        N = merged_df[\"Northing_local\"].values\n        \n        # Determine weights\n        sigma_col = \"sigma_global\" if \"sigma_global\" in merged_df.columns else \"sigma\"\n        if sigma_col in merged_df.columns:\n            sigmas = merged_df[sigma_col].values\n            sigmas_safe = np.where(sigmas > 0, sigmas, 1.0)\n            w_sqrt = 1.0 / sigmas_safe\n        else:\n            w_sqrt = np.ones(n)\n            \n        w_sq = w_sqrt ** 2\n        sum_w = float(np.sum(w_sq))\n\n        # --- Horizontal Adjustment ---\n        a, b, x_c, y_c, E_c, N_c, outlier_flags_h, sigma0_sq_h, local_control_pts = calculate_wls_similarity(\n            x, y, E, N, w_sq, sum_w, w_sqrt, n\n        )\n        \n        tE = E_c - a * x_c + b * y_c\n        tN = N_c - b * x_c - a * y_c\n        \n        self.horizontal_params = HorizontalParams(\n            a=a, b=b, x_c=x_c, y_c=y_c, E_c=E_c, N_c=N_c,\n            tE=tE, tN=tN,\n            local_control_points=local_control_pts.tolist()\n        ).model_dump()\n\n        # --- Vertical Adjustment ---\n        h_global = merged_df[\"EllipsoidalHeight\"].values \n        h_local = merged_df[\"Elevation\"].values\n        Z_error = h_global - h_local\n        \n        # We need N_prime and E_prime for the vertical planar fit domain\n        E_prime = E - E_c\n        N_prime = N - N_c\n        \n        C, slope_n, slope_e, rank, bad_geom, bad_cond, outlier_flags_v, sigma0_sq_v = calculate_wls_vertical(\n            Z_error, E_prime, N_prime, w_sq, sum_w, w_sqrt, n, N_c, E_c\n        )\n            \n        self.vertical_params = VerticalParams(\n            vertical_shift=C,\n            slope_north=slope_n,\n            slope_east=slope_e,\n            centroid_north=N_c,\n            centroid_east=E_c,\n            rank=rank,\n            bad_geometry=bad_geom,\n            bad_condition=bad_cond\n        ).model_dump()\n        \n        # Calculate residuals & Transformed Values\n        transformed = self.transform(merged_df)\n        self.residuals = pd.DataFrame({\n            \"Point\": merged_df[\"Point\"],\n            \"dE\": transformed[\"Easting\"] - merged_df[\"Easting_local\"],\n            \"dN\": transformed[\"Northing\"] - merged_df[\"Northing_local\"],\n            \"dH\": transformed[\"h\"] - merged_df.get(\"Elevation\", 0) - (merged_df.get(\"EllipsoidalHeight\", 0) - merged_df.get(\"Elevation\", 0)), \n            \"outlier_horizontal\": outlier_flags_h,\n            \"outlier_vertical\": outlier_flags_v\n        })\n        self.residuals[\"dH\"] = transformed[\"h\"] - merged_df[\"Elevation\"]\n\n\n    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n        if self.horizontal_params is None or self.vertical_params is None:\n            raise RuntimeError(\"The calibration model has not been trained.\")\n        \n        # Horizontal\n        a = self.horizontal_params[\"a\"]\n        b = self.horizontal_params[\"b\"]\n        x_c = self.horizontal_params[\"x_c\"]\n        y_c = self.horizontal_params[\"y_c\"]\n        E_c = self.horizontal_params[\"E_c\"]\n        N_c = self.horizontal_params[\"N_c\"]\n\n        # Vertical\n        C = self.vertical_params[\"vertical_shift\"]\n        Sn = self.vertical_params[\"slope_north\"]\n        Se = self.vertical_params[\"slope_east\"]\n        Nc = self.vertical_params[\"centroid_north\"]\n        Ec = self.vertical_params[\"centroid_east\"]\n\n        # Pydantic validation\n        valid_pts = [PointTransform(**row) for row in df.to_dict('records')]\n\n        # Handle column names dynamically\n        if \"Easting_global\" in df.columns:\n            x = df[\"Easting_global\"].values\n            y = df[\"Northing_global\"].values\n        else:\n            x = df[\"Easting\"].values\n            y = df[\"Northing\"].values\n            \n        # Vertical Height Selection (Global First)\n        if \"EllipsoidalHeight\" in df.columns:\n             h_input = df[\"EllipsoidalHeight\"].values\n        elif \"Elevation\" in df.columns:\n             # Fallback for purely local ops (uncommon in strict transformations)\n             h_input = df[\"Elevation\"].values\n        else:\n             h_input = np.zeros(len(df))\n\n        # Apply 2D Sim\n        E_trans = a * (x - x_c) - b * (y - y_c) + E_c\n        N_trans = b * (x - x_c) + a * (y - y_c) + N_c\n        \n        # Extrapolation Warning using ConvexHull\n        # We need at least 3 points, non-collinear, to form a hull.\n        local_pts_list = self.horizontal_params.get(\"local_control_points\")\n        if local_pts_list is not None:\n            local_pts = np.array(local_pts_list)\n            max_out_dist, count_out = check_extrapolation(E_trans, N_trans, local_pts)\n            if max_out_dist is not None:\n                import warnings\n                warnings.warn(f\"Extrapolaci\u00f3n detectada: {count_out} puntos caen fuera del pol\u00edgono de control. Distancia m\u00e1xima al borde: {max_out_dist:.3f}m\")\n        \n        # Apply Vertical Adjustment\n        # We need N_local and E_local for the plane. \n        # If we only have global input (transforming global to local), we use the transformed values as proxy for position\n        # Or if we have local columns in input.\n        \n        # The plane Z_err = C + Sn*(N - Nc) + Se*(E - Ec)\n        # Z_local_derived = Z_global - Z_err (if subtracting error) or Z_local + Z_adj = Z_global\n        # Let's align with the training: Z_error = Z_global - Z_local\n        # So Z_global = Z_local + Z_error\n        # We want to output \"Transformed\" coords. Usually this means transforming GNSS (Global) -> Local Grid.\n        # But wait, TBC Site Cal transforms GPS (Global) to Grid (Local).\n        # My train code defined a,b,tE,tN such that Local = f(Global).\n        # So E_trans IS the estimated Local Easting.\n        # So we can use E_trans and N_trans for the inclined plane domain.\n        \n        dZ = C + Sn * (N_trans - Nc) + Se * (E_trans - Ec)\n        \n        # wait, input 'h' in transform might be global h?\n        # If input is global list, we want to match Local.\n        # In train: Z_error = H_global - H_local.\n        # This implies H_global = H_local + Z_error => H_local = H_global - Z_error.\n        # If the user passes global coords to transform(), they expect Local Grid coords out.\n        # So H_out = H_in (Global) - dZ.\n        \n        # Let's verify standard: Site Cal applied to GPS point:\n        # 1. Convert Lat/Lon to Transverse Mercator (if not already) -> Global Grid\n        # 2. Apply Horizontal Adjust -> Local Grid N,E\n        # 3. Apply Vertical Adjust -> Local Elev.\n        \n        # If Z_error was defined as Global - Local (positive means Global is higher)\n        # Then Local = Global - Z_error. \n        # Yes.\n        \n        H_trans = h_input - dZ\n        # Let's assume input to transform is \"Source\" (Global).\n        \n        return pd.DataFrame({\n            \"Point\": df[\"Point\"],\n            \"Easting\": E_trans,\n            \"Northing\": N_trans,\n            \"h\": H_trans\n        })\n\n    def transform_inverse(self, df: pd.DataFrame) -> pd.DataFrame:\n        if self.horizontal_params is None or self.vertical_params is None:\n            raise RuntimeError(\"The calibration model has not been trained.\")\n        \n        # Horizontal\n        a = self.horizontal_params[\"a\"]\n        b = self.horizontal_params[\"b\"]\n        x_c = self.horizontal_params[\"x_c\"]\n        y_c = self.horizontal_params[\"y_c\"]\n        E_c = self.horizontal_params[\"E_c\"]\n        N_c = self.horizontal_params[\"N_c\"]\n\n        # Vertical\n        C = self.vertical_params[\"vertical_shift\"]\n        Sn = self.vertical_params[\"slope_north\"]\n        Se = self.vertical_params[\"slope_east\"]\n        Nc = self.vertical_params[\"centroid_north\"]\n        Ec = self.vertical_params[\"centroid_east\"]\n\n        # Handle column names dynamically\n        if \"Easting_local\" in df.columns:\n            E_in = df[\"Easting_local\"].values\n            N_in = df[\"Northing_local\"].values\n        else:\n            E_in = df[\"Easting\"].values if \"Easting\" in df.columns else np.zeros(len(df))\n            N_in = df[\"Northing\"].values if \"Northing\" in df.columns else np.zeros(len(df))\n            \n        if \"Elevation\" in df.columns:\n            h_local = df[\"Elevation\"].values\n        elif \"h\" in df.columns:\n            h_local = df[\"h\"].values\n        else:\n            h_local = np.zeros(len(df))\n\n        scale_sq = a**2 + b**2\n        \n        # Apply Inverse 2D Sim\n        x_global = x_c + (a * (E_in - E_c) + b * (N_in - N_c)) / scale_sq\n        y_global = y_c + (-b * (E_in - E_c) + a * (N_in - N_c)) / scale_sq\n        \n        # Apply Inverse Vertical\n        dZ = C + Sn * (N_in - Nc) + Se * (E_in - Ec)\n        H_global = h_local + dZ\n        \n        df_out = {\n            \"Point\": df[\"Point\"] if \"Point\" in df.columns else np.arange(len(df)),\n            \"EllipsoidalHeight\": H_global\n        }\n        \n        # Deproject with PyProj to obtain Lat/Lon\n        if self.proj_method:\n            from pyproj import CRS, Transformer\n            src_str, dst_str = self.get_crs_strings()\n            if dst_str:\n                src_crs = CRS(dst_str)\n                dst_crs = CRS(src_str)\n                transformer = Transformer.from_crs(src_crs, dst_crs, always_xy=True)\n                lon, lat = transformer.transform(x_global, y_global)\n                df_out[\"Latitude\"] = lat\n                df_out[\"Longitude\"] = lon\n            else:\n                df_out[\"Easting_global\"] = x_global\n                df_out[\"Northing_global\"] = y_global\n        else:\n            df_out[\"Easting_global\"] = x_global\n            df_out[\"Northing_global\"] = y_global\n        \n        return pd.DataFrame(df_out)\n\n    def save(self) -> str:\n        if self.horizontal_params is None or self.vertical_params is None:\n            raise RuntimeError(\"The calibration model has not been trained.\")\n            \n        data = {\n            \"method\": \"similarity2d\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"projection\": {\n                \"method\": self.proj_method,\n                \"params\": self.proj_params\n            },\n            \"parameters\": {\n                \"horizontal\": self.horizontal_params,\n                \"vertical\": self.vertical_params\n            }\n        }\n        return json.dumps(data, indent=4)\n\n    @classmethod\n    def load(cls, json_str: str) -> 'Similarity2D':\n        data = json.loads(json_str)\n        if data.get(\"method\") != \"similarity2d\":\n            raise ValueError(f\"Invalid method in sitecal file: {data.get('method')}\")\n            \n        params = data.get(\"parameters\", {})\n        proj_data = data.get(\"projection\", {})\n        \n        instance = cls()\n        instance.horizontal_params = params.get(\"horizontal\")\n        instance.vertical_params = params.get(\"vertical\")\n        instance.proj_method = proj_data.get(\"method\")\n        instance.proj_params = proj_data.get(\"params\", {})\n        \n        if not instance.horizontal_params or not instance.vertical_params:\n            raise ValueError(\"Missing parameters in the loaded model.\")\n            \n        return instance\n\n\n\nclass CalibrationFactory:\n    @staticmethod\n    def create(method: str) -> Calibration:\n        if method == \"default\" or method == \"ltm\":\n            return Similarity2D()\n        else:\n            raise ValueError(f\"Unknown calibration method: {method}\")", "sitecal/core/math_engine.py": "import numpy as np\nfrom typing import Tuple, Dict, Any, Optional\n\ndef calculate_wls_similarity(\n    x: np.ndarray, y: np.ndarray, \n    E: np.ndarray, N: np.ndarray, \n    w_sq: np.ndarray, sum_w: float, w_sqrt: np.ndarray, n: int\n) -> Tuple[float, float, float, float, float, float, np.ndarray, float, np.ndarray]:\n    \"\"\"Calculates WLS Horizontal Similarity parameters.\"\"\"\n    \n    # Calculate weighted centroids\n    x_c = np.sum(w_sq * x) / sum_w\n    y_c = np.sum(w_sq * y) / sum_w\n    E_c = np.sum(w_sq * E) / sum_w\n    N_c = np.sum(w_sq * N) / sum_w\n    \n    # Center coordinates\n    x_prime = x - x_c\n    y_prime = y - y_c\n    E_prime = E - E_c\n    N_prime = N - N_c\n\n    # Validations for Horizontal Adjustment\n    if n < 2:\n        raise ValueError(\"Se requieren al menos 2 puntos para el ajuste horizontal.\")\n\n    coords_matrix = np.column_stack((E_prime, N_prime))\n    if np.linalg.matrix_rank(coords_matrix, tol=1e-5) < 2 and n >= 3:\n        raise ValueError(\"Geometr\u00eda deficiente\")\n\n    # Solve for a and b using centered coordinates\n    A = np.zeros((2 * n, 2))\n    A[:n, 0] = x_prime\n    A[:n, 1] = -y_prime\n    A[n:, 0] = y_prime\n    A[n:, 1] = x_prime\n\n    L = np.concatenate([E_prime, N_prime])\n\n    w_sqrt_2n = np.concatenate([w_sqrt, w_sqrt])\n    A_w = A * w_sqrt_2n[:, np.newaxis]\n    L_w = L * w_sqrt_2n\n\n    params_ab, _, _, _ = np.linalg.lstsq(A_w, L_w, rcond=None)\n    a = params_ab[0]\n    b = params_ab[1]\n    \n    # --- Baarda Data Snooping (Horizontal) ---\n    dof_h = 2 * n - 4\n    outlier_flags_h = np.zeros(n, dtype=bool)\n    \n    if dof_h > 0:\n        V_h = A_w @ params_ab - L_w\n        sigma0_sq_h = np.dot(V_h, V_h) / dof_h\n        \n        if sigma0_sq_h > 1e-12:\n            N_mat_h = A_w.T @ A_w\n            try:\n                N_inv_h = np.linalg.inv(N_mat_h)\n                diag_Q_hat = np.sum((A_w @ N_inv_h) * A_w, axis=1)\n                diag_Q_vv = 1.0 - diag_Q_hat\n                \n                diag_Q_vv_safe = np.maximum(diag_Q_vv, 1e-12)\n                w_stat = V_h / (np.sqrt(sigma0_sq_h) * np.sqrt(diag_Q_vv_safe))\n                \n                w_stat_E = w_stat[:n]\n                w_stat_N = w_stat[n:]\n                max_w_stat = np.maximum(np.abs(w_stat_E), np.abs(w_stat_N))\n                \n                critical_value = 3.0\n                outlier_flags_h = max_w_stat > critical_value\n            except np.linalg.LinAlgError:\n                pass\n\n    return a, b, x_c, y_c, E_c, N_c, outlier_flags_h, sigma0_sq_h if dof_h > 0 else 0.0, np.column_stack((E_prime, N_prime))\n\n\ndef calculate_wls_vertical(\n    Z_error: np.ndarray, E_prime: np.ndarray, N_prime: np.ndarray, \n    w_sq: np.ndarray, sum_w: float, w_sqrt: np.ndarray, n: int, \n    N_c: float, E_c: float\n) -> Tuple[float, float, float, int, bool, bool, np.ndarray, float]:\n    \"\"\"Calculates WLS Vertical parameters.\"\"\"\n    bad_vertical_geometry = False\n    bad_condition = False\n    \n    if n >= 3:\n        A_v = np.ones((n, 3))\n        A_v[:, 1] = N_prime\n        A_v[:, 2] = E_prime\n        \n        A_v_w = A_v * w_sqrt[:, np.newaxis]\n        Z_error_w = Z_error * w_sqrt\n        \n        v_params, _, rank, _ = np.linalg.lstsq(A_v_w, Z_error_w, rcond=None)\n        \n        if rank < 3:\n            bad_vertical_geometry = True\n            C = np.sum(w_sq * Z_error) / sum_w\n            slope_n = 0.0\n            slope_e = 0.0\n        else:\n            cond = np.linalg.cond(A_v)\n            if cond > 1e10:\n                bad_condition = True\n\n            C = v_params[0]\n            slope_n = v_params[1]\n            slope_e = v_params[2]\n    else:\n        C = np.sum(w_sq * Z_error) / sum_w\n        slope_n = 0.0\n        slope_e = 0.0\n        rank = 1\n        A_v_w = np.ones((n, 1)) * w_sqrt[:, np.newaxis]\n        v_params = np.array([C])\n        Z_error_w = Z_error * w_sqrt\n        \n    # --- Baarda Data Snooping (Vertical) ---\n    num_v_params = 3 if (n >= 3 and rank >= 3) else 1\n    dof_v = n - num_v_params\n    outlier_flags_v = np.zeros(n, dtype=bool)\n    sigma0_sq_v = 0.0\n    \n    if dof_v > 0 and 'A_v_w' in locals():\n        V_v = A_v_w @ v_params - Z_error_w\n        sigma0_sq_v = np.dot(V_v, V_v) / dof_v\n        \n        if sigma0_sq_v > 1e-12:\n            N_mat_v = A_v_w.T @ A_v_w\n            try:\n                N_inv_v = np.linalg.inv(N_mat_v)\n                diag_Q_hat_v = np.sum((A_v_w @ N_inv_v) * A_v_w, axis=1)\n                diag_Q_vv_v = 1.0 - diag_Q_hat_v\n                \n                diag_Q_vv_v_safe = np.maximum(diag_Q_vv_v, 1e-12)\n                w_stat_v = V_v / (np.sqrt(sigma0_sq_v) * np.sqrt(diag_Q_vv_v_safe))\n                \n                critical_value = 3.0\n                outlier_flags_v = np.abs(w_stat_v) > critical_value\n            except np.linalg.LinAlgError:\n                pass\n                \n    return C, slope_n, slope_e, rank, bad_vertical_geometry, bad_condition, outlier_flags_v, sigma0_sq_v\n\ndef check_extrapolation(E_trans: np.ndarray, N_trans: np.ndarray, local_pts: np.ndarray) -> Optional[float]:\n    \"\"\"Calculates extrapolation distance. Returns max distance if outside, else None.\"\"\"\n    if local_pts is not None and len(local_pts) >= 3:\n        try:\n            from scipy.spatial import ConvexHull\n            from scipy.spatial.qhull import QhullError\n            \n            try:\n                hull = ConvexHull(local_pts)\n                equations = hull.equations\n                trans_pts = np.column_stack((E_trans, N_trans))\n                dists = np.dot(trans_pts, equations[:, :2].T) + equations[:, 2]\n                max_dists = np.max(dists, axis=1)\n                epsilon = 1e-5\n                outside_mask = max_dists > epsilon\n                \n                if np.any(outside_mask):\n                    return np.max(max_dists[outside_mask]), np.sum(outside_mask)\n            except QhullError:\n                pass\n        except ImportError:\n            pass\n    return None, 0\n", "sitecal/core/projections.py": "from abc import ABC, abstractmethod\nimport numpy as np\nimport pandas as pd\nfrom pyproj import CRS, Transformer\nfrom pyproj.exceptions import ProjError\n\n\nclass Projection(ABC):\n    @abstractmethod\n    def project(self, df: pd.DataFrame) -> pd.DataFrame:\n        pass\n\n\nclass Default(Projection):\n    def project(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Uses the first point as the origin (0,0) and a scale factor of 1.\n        This creates a local Transverse Mercator projection centered on the project.\n        \"\"\"\n        if df.empty:\n            raise ValueError(\"Cannot project empty DataFrame. Need at least one point to define origin.\")\n\n        # Use the first point as the projection origin\n        lat_0 = df.iloc[0][\"Latitude\"]\n        lon_0 = df.iloc[0][\"Longitude\"]\n        \n        # Define projection: TM, Origin at 1st point, Scale 1.0, FE 0, FN 0\n        proj_string = (\n            f\"+proj=tmerc +lat_0={lat_0} +lon_0={lon_0} \"\n            f\"+k=1.0 +x_0=0 +y_0=0 \"\n            f\"+ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n        )\n        \n        src_crs = CRS(\"EPSG:4326\")  # WGS84 Geodetic\n        dst_crs = CRS(proj_string)\n\n        transformer = Transformer.from_crs(src_crs, dst_crs, always_xy=True)\n\n        try:\n            # Transform all points to this local system\n            easting, northing = transformer.transform(df[\"Longitude\"].values, df[\"Latitude\"].values)\n            \n            df_out = df.copy()\n            df_out[\"Easting\"] = easting\n            df_out[\"Northing\"] = northing\n            return df_out\n            \n        except ProjError as e:\n            raise RuntimeError(f\"Default Projection failed: {e}\")\n\n\nclass UTM(Projection):\n    def project(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Projects geodetic coordinates (Lat, Lon) to UTM.\n        The UTM zone is automatically determined from the mean longitude.\n        \"\"\"\n        if df.empty:\n             raise ValueError(\"Cannot project empty DataFrame\")\n\n        lon_mean = df[\"Longitude\"].mean()\n        # Simple UTM zone calculation\n        utm_zone = int((lon_mean + 180) / 6) + 1\n        \n        src_crs = CRS(\"EPSG:4326\")  # WGS84\n        # Assuming southern hemisphere for Chile/South America focus, \n        # but technically should check Lat. keeping simple for MVP.\n        is_south = df[\"Latitude\"].mean() < 0\n        epsg_code = 32700 + utm_zone if is_south else 32600 + utm_zone\n        \n        dst_crs = CRS(f\"EPSG:{epsg_code}\")\n\n        transformer = Transformer.from_crs(src_crs, dst_crs, always_xy=True)\n\n        try:\n            easting, northing = transformer.transform(df[\"Longitude\"].values, df[\"Latitude\"].values)\n            df_out = df.copy()\n            df_out[\"Easting\"] = easting\n            df_out[\"Northing\"] = northing\n            return df_out\n        except ProjError as e:\n            raise RuntimeError(f\"UTM Projection failed: {e}\")\n\n\nclass LTM(Projection):\n    def __init__(self, central_meridian, latitude_of_origin, false_easting, false_northing, scale_factor):\n        self.central_meridian = central_meridian\n        self.latitude_of_origin = latitude_of_origin\n        self.false_easting = false_easting\n        self.false_northing = false_northing\n        self.scale_factor = scale_factor\n\n    def project(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Projects geodetic coordinates to a custom LTM projection.\n        \"\"\"\n        if df.empty:\n             raise ValueError(\"Cannot project empty DataFrame\")\n\n        proj_string = (\n            f\"+proj=tmerc +lat_0={self.latitude_of_origin} +lon_0={self.central_meridian} \"\n            f\"+k={self.scale_factor} +x_0={self.false_easting} +y_0={self.false_northing} \"\n            f\"+ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n        )\n        \n        src_crs = CRS(\"EPSG:4326\")  # WGS84\n        dst_crs = CRS(proj_string)\n\n        transformer = Transformer.from_crs(src_crs, dst_crs, always_xy=True)\n        \n        try:\n            easting, northing = transformer.transform(df[\"Longitude\"].values, df[\"Latitude\"].values)\n            df_out = df.copy()\n            df_out[\"Easting\"] = easting\n            df_out[\"Northing\"] = northing\n            return df_out\n        except ProjError as e:\n            raise RuntimeError(f\"LTM Projection failed: {e}\")\n\n\nclass EPSG(Projection):\n    def __init__(self, epsg_code: int):\n        self.epsg_code = int(epsg_code)\n\n    def project(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Projects geodetic coordinates (Lat, Lon) using any EPSG code via PyProj.\n        \"\"\"\n        if df.empty:\n            raise ValueError(\"Cannot project empty DataFrame\")\n\n        src_crs = CRS(\"EPSG:4326\")\n        try:\n            dst_crs = CRS(f\"EPSG:{self.epsg_code}\")\n        except Exception as e:\n            raise ValueError(f\"Invalid EPSG code {self.epsg_code}: {e}\")\n\n        transformer = Transformer.from_crs(src_crs, dst_crs, always_xy=True)\n\n        try:\n            easting, northing = transformer.transform(df[\"Longitude\"].values, df[\"Latitude\"].values)\n            df_out = df.copy()\n            df_out[\"Easting\"] = easting\n            df_out[\"Northing\"] = northing\n            return df_out\n        except ProjError as e:\n            raise RuntimeError(f\"EPSG:{self.epsg_code} Projection failed: {e}\")\n\n\nclass ProjectionFactory:\n    @staticmethod\n    def create(method: str, **kwargs) -> Projection:\n        if method == \"default\":\n            return Default()\n        elif method == \"utm\":\n            return UTM()\n        elif method == \"ltm\":\n            return LTM(\n                central_meridian=kwargs.get(\"central_meridian\"),\n                latitude_of_origin=kwargs.get(\"latitude_of_origin\"),\n                false_easting=kwargs.get(\"false_easting\"),\n                false_northing=kwargs.get(\"false_northing\"),\n                scale_factor=kwargs.get(\"scale_factor\"),\n            )\n        elif method == \"epsg\":\n            return EPSG(epsg_code=kwargs.get(\"epsg_code\"))\n        else:\n            raise ValueError(f\"Unknown projection method: {method}\")\n        ", "sitecal/domain/schemas.py": "from typing import Optional, List\nfrom pydantic import BaseModel, Field, conlist, model_validator\n\n\nclass PointLocal(BaseModel):\n    Point: str\n    Easting: float = Field(alias=\"Easting_local\")\n    Northing: float = Field(alias=\"Northing_local\")\n    Elevation: float\n\n    # Allow initializing without alias to match raw DataFrame\n    model_config = {\"populate_by_name\": True}\n\n\nclass PointGlobal(BaseModel):\n    Point: str\n    Easting: float = Field(alias=\"Easting_global\")\n    Northing: float = Field(alias=\"Northing_global\")\n    EllipsoidalHeight: float\n    sigma_global: Optional[float] = None\n    sigma: Optional[float] = None\n\n    model_config = {\"populate_by_name\": True}\n\n\nclass PointTransform(BaseModel):\n    Point: str\n    Easting_global: Optional[float] = None\n    Northing_global: Optional[float] = None\n    Easting: Optional[float] = None\n    Northing: Optional[float] = None\n    EllipsoidalHeight: Optional[float] = None\n    Elevation: Optional[float] = None\n\n    @model_validator(mode='after')\n    def check_coordinates(self) -> 'PointTransform':\n        has_global = self.Easting_global is not None and self.Northing_global is not None\n        has_local = self.Easting is not None and self.Northing is not None\n        if not (has_global or has_local):\n            raise ValueError(\"Must provide either Easting_global/Northing_global or Easting/Northing\")\n        return self\n\n\nclass HorizontalParams(BaseModel):\n    a: float\n    b: float\n    x_c: float\n    y_c: float\n    E_c: float\n    N_c: float\n    tE: float\n    tN: float\n    local_control_points: List[List[float]]\n\n\nclass VerticalParams(BaseModel):\n    vertical_shift: float\n    slope_north: float\n    slope_east: float\n    centroid_north: float\n    centroid_east: float\n    rank: int\n    bad_geometry: bool\n    bad_condition: bool\n", "sitecal/infrastructure/reports.py": "import pandas as pd\nfrom sitecal.core.calibration_engine import Calibration\nimport datetime\nimport pytz\n\ndef generate_markdown_report(\n    calibration: Calibration,\n    output_path: str,\n    method: str\n):\n    \"\"\"\n    Generates a Markdown report with calibration results.\n    \"\"\"\n    \n    report_lines = []\n    \n    now = datetime.datetime.now(pytz.timezone('America/Santiago')).strftime(\"%Y-%m-%d %H:%M:%S\")\n    \n    report_lines.append(\"# Site Calibration Report\")\n    report_lines.append(\"\")\n    report_lines.append(f\"Report generated on: {now}\")\n    report_lines.append(\"\")\n    report_lines.append(f\"## Calibration Method: {method.upper()}\")\n    report_lines.append(\"\")\n\n    # Horizontal Transformation Parameters (2D)\n    report_lines.append(\"### \ud83c\udfd7\ufe0f Ajuste Horizontal (2D)\")\n    report_lines.append(\"\")\n    if calibration.horizontal_params:\n        hp = calibration.horizontal_params\n        report_lines.append(\"- **Factor de Escala (a):** \" + f\"`{hp['a']:.6f}`\")\n        report_lines.append(\"- **T\u00e9rmino de Rotaci\u00f3n (b):** \" + f\"`{hp['b']:.6f}`\")\n        report_lines.append(\"- **Traslaci\u00f3n Este:** \" + f\"`{hp['tE']:.3f} m`\")\n        report_lines.append(\"- **Traslaci\u00f3n Norte:** \" + f\"`{hp['tN']:.3f} m`\")\n        \n        # Derived: Scale and Rotation\n        scale = (hp['a']**2 + hp['b']**2)**0.5\n        import math\n        rotation_rad = math.atan2(hp['b'], hp['a'])\n        rotation_deg = math.degrees(rotation_rad)\n        rotation_dms_d = int(rotation_deg)\n        rotation_dms_m = int((abs(rotation_deg) - abs(rotation_dms_d)) * 60)\n        rotation_dms_s = (abs(rotation_deg) - abs(rotation_dms_d) - rotation_dms_m/60) * 3600\n        \n        report_lines.append(f\"- **Escala Impl\u00edcita:** `{scale:.8f}`\")\n        report_lines.append(f\"- **Rotaci\u00f3n Impl\u00edcita:** `{rotation_dms_d}\u00b0 {rotation_dms_m}' {rotation_dms_s:.1f}\\\"`\")\n\n    else:\n        report_lines.append(\"No se calcularon par\u00e1metros horizontales.\")\n    report_lines.append(\"\")\n    \n    # Vertical Adjustment Parameters (Inclined Plane)\n    report_lines.append(\"### \ud83d\udcd0 Ajuste Vertical (1D)\")\n    report_lines.append(\"\")\n    if calibration.vertical_params:\n        vp = calibration.vertical_params\n        report_lines.append(f\"- **Desplazamiento Vertical (Shift):** `{vp['vertical_shift']:.3f} m`\")\n        report_lines.append(f\"- **Inclinaci\u00f3n Norte:** `{vp['slope_north']*1e6:.2f} ppm`\")\n        report_lines.append(f\"- **Inclinaci\u00f3n Este:** `{vp['slope_east']*1e6:.2f} ppm`\")\n        report_lines.append(f\"- **Centroide (N, E):** `({vp['centroid_north']:.3f}, {vp['centroid_east']:.3f})`\")\n    else:\n        report_lines.append(\"No se calcularon par\u00e1metros verticales.\")\n    report_lines.append(\"\")\n\n    # Residuals Table\n    report_lines.append(\"### Residuals (mm)\")\n    report_lines.append(\"\")\n    if calibration.residuals is not None:\n        residuals_mm = calibration.residuals.copy()\n        residuals_mm[\"dE\"] = (residuals_mm[\"dE\"] * 1000).round(1)\n        residuals_mm[\"dN\"] = (residuals_mm[\"dN\"] * 1000).round(1)\n        residuals_mm[\"dH\"] = (residuals_mm[\"dH\"] * 1000).round(1)\n        residuals_mm.rename(columns={\"dE\": \"dE (mm)\", \"dN\": \"dN (mm)\", \"dH\": \"dH (mm)\"}, inplace=True)\n        report_lines.append(residuals_mm.to_markdown(index=False))\n    else:\n        report_lines.append(\"No residuals were calculated.\")\n    report_lines.append(\"\")\n\n    # Statistics\n    report_lines.append(\"### Statistics\")\n    report_lines.append(\"\")\n    if calibration.residuals is not None:\n        residuals = calibration.residuals\n        # Calculate horizontal error\n        residuals[\"error_h\"] = (residuals[\"dE\"]**2 + residuals[\"dN\"]**2)**0.5\n        \n        worst_point = residuals.loc[residuals[\"error_h\"].idxmax()]\n        best_point = residuals.loc[residuals[\"error_h\"].idxmin()]\n        std_dev = residuals[[\"dE\", \"dN\", \"dH\"]].std().to_dict()\n        percentile_99 = residuals[\"error_h\"].quantile(0.99)\n\n        report_lines.append(f\"- **Worst Point:** `{worst_point['Point']}` (Error: {(worst_point['error_h'] * 1000):.1f} mm)\")\n        report_lines.append(f\"- **Best Point:** `{best_point['Point']}` (Error: {(best_point['error_h'] * 1000):.1f} mm)\")\n        report_lines.append(\"- **Standard Deviations (mm):**\")\n        for axis, value in std_dev.items():\n            report_lines.append(f\"  - `{axis}`: {(value * 1000):.1f} mm\")\n        report_lines.append(f\"- **99th Percentile of Horizontal Errors:** {(percentile_99 * 1000):.1f} mm\")\n\n    else:\n        report_lines.append(\"Statistics could not be calculated.\")\n    report_lines.append(\"\")\n\n    return \"\\n\".join(report_lines) + \"\\n\"\n" }
      },
      document.getElementById("root")
    );
  </script>
</body>

</html>